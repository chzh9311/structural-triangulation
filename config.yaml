file_paths:
  # 2D detection data file, pre-processing and 2D backbone model source: https://github.com/karfly/learnable-triangulation-pytorch
  # including the following contents:
  # keypoints_2d: a list of numpy.ndarray of size batch_size x n_cameras x n_joints x 2. The 2D keypoint estimations.
  # keypoints_3d_gt: a list of numpy.ndarray of size batch_size x n_joints x 3. The 3D ground truth.
  # confidences: a list of numpy.ndarray of batch_size x n_cam x 17, The 2D confidences of each joint.
  # Projections: a list of numpy.ndarray of size batch_size x n_cameras x 3 x 4. The camera projection matrices.
  # action_idx: a vector of dimension n_frames, indicating the action indices.
  # subject_idx: a vector of dimension n_frames, indicating the subject indices.
  detected_data: data/detected_data.pkl

  # The bone lengths of test subjects.
  bl_S9: bone_lengths/h36m/S9_bl_gt.npy
  bl_S11: bone_lengths/h36m/S11_bl_gt.npy

data:
  # The joint number
  n_joints: 17

  # order of joints used in triangulation process.
  flip_pairs:
    -
      - 0
      - 6

  # Action names
  actions:
    - Directions
    - Discussion
    - Eating
    - Greeting
    - Phoning
    - Posing
    - Purchases
    - Sitting
    - SittingDown
    - Smoking
    - TakingPhoto
    - Waiting
    - Walking
    - WalkingDog
    - WalkingTogether

test:
  # The step number of Step constraint method
  method: ST
  SCA_step: 3
  with_damaged_actions: True
